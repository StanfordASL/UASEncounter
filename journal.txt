Fri 13 Mar 2015 11:58:22 PM PDT
still weird value - run 50k more!


Fri 13 Mar 2015 08:25:06 PM PDT
Turning now performs poorly, but does perform...
Still can't beat static trl

[X] make policy viewer for pd policies
[ ] look at some individual simulations
    [ ] sim plotter
[X] Re-parallelize
[X] plot the initial conditions
    [X] arrow plotter
[X] Test random sim

Things to try
[ ] increase arena size
[X] penalize deviation
[ ] decrease noise (this probably won't work)

PENALIZING DEVIATION!

??? Turning policies still look really bad - increase simulations?
??? why does pd value function have values lower than in a collision
NOPE maybe the rng_seed_offset is causing some bias

Thu 12 Mar 2015 01:17:25 AM PDT
tested and fixed ic batch generation (I think)
why does turning still not work well? look at some encounters
really seems like pd might work

Wed 11 Mar 2015 03:56:45 AM PDT
morning
[ ] post-mortem on pinv - why is the batch not making it full rank
[ ] start pd sims

Mon 09 Mar 2015 09:33:10 PM PDT
turning is being rediculous. Why?

1. [ ] Looks like it might be something to do with the grid - introduce the DAMN snapping
2. [ ] post-decision state

Mon 09 Mar 2015 03:33:30 AM PDT
Seems like deviations might be causing a problem - try without

Sun 08 Mar 2015 05:48:39 PM PDT

[X] slog through presentation
[ ] Make a case for using post decision state [independent Q-value functions introduce paradoxical results: actions resulting in the same expected next state can have different values]
[X] run trl sweep with 100 150 200 230
[ ] run trl sweep with 100 150 200 250 300
[ ] implement post-decision policy
[ ] Look at why the acceleration causes so many diversions

TRL Lagrange sweep Mar 8 1812
D = 100, 150, 200, 300, 500
rr = 0.045
deviations = 7627
avg_delay = 6.27


Sun 08 Mar 2015 01:04:27 PM PDT
Not able to make .05 rr with 15 deg noise! See Mar 6 though - the static trl could make it
SWITCHING TO 10!
with 10 deg noise, trl makes 0.05 with lambda=1000
with 10 deg noise static trl makes 0.0495 with D = 230

This looks like the new baseline point for static trl is
D = 230
rr = 0.05
deviations = 6800
avg_delay = 5 (? adjusted for double counting)

[X] have bisect save everything
[X] change trl actions to go from 100 to 500
[X] run trl with lower lambda
[X] make sweep save periodically


Sat 07 Mar 2015 11:03:16 AM PST
[X] bisect with accel actions
    [X] generate no collision ics
    swept log from 1000 to 1e6. lowest rr was 0.0825 at lambda = 178k
    saved in data/first_lagrange_bisection.jld
[ ] look at trl policy
[X] bisect with trl actions

Fri 06 Mar 2015 10:17:50 PM PST
[X] generate ics that cause nmacs
[X] bisect the static TRL Parameter to achieve risk ratio
    with 500.0 min starting dist, 0.1 rr seems achievable, but anything less than 0.9 is not
    with 800.0 min starting dist 0.05 seems achievable
    D = 780 => rr=0.045 for 0.05 desired rr

RED FLAG: randomness doesn't seem to be working quite right

Fri 06 Mar 2015 05:00:41 PM PST
[X] deviated feature
[X] run test
[X] decrease hrl precision


Wed 04 Mar 2015 01:14:57 PM PST
    probably time to just go ahead and switch reward functions
    policy weirdness: 50k helps - make sure to run 50k on last value iteration
    do this now
    [X] Do first two problems of homework
    [X] Major Refactoring - tonight
        [X] lambda -> theta everywhere
        [X] refactor features [test speed!]
        [X] augment state
        [X] refactor reward function

Wed 04 Mar 2015 12:37:12 AM PST
tomorrow
1. understand policies
    problem (?) the policy is mostly determined by quirks of the feature fit
        solutions: change reward function...
            snap to goal grid as well as intruder grid
            think about whether post-decision state might be better...
2. start homework
3. reward function change

Tue 03 Mar 2015 03:37:19 PM PST
[X] Plot policies
    [N] Consider pgfplots
        [X] Import speed - PGF takes about 10s, Pyplot about 20s
        [ ] Image Performance
        [ ] Arrows
    [ ] Plot policy only where it matters
[X] Rerun simulations with more actions

Mon 02 Mar 2015 11:19:16 PM PST
comparing pinv with l_bfgs
pinv takes 85 seconds to invert on Theresa
lbfgs 433 seconds the first time, 384 the second, 270, 277 - this is not competitive

Mon 02 Mar 2015 01:17:20 PM PST
ran some tests with snap generation - doesn't fill the space very well... maybe need to generate one for each node at least
Phi size: 50k x 1882, Phi rank:1706
[X] generate ics on all gridpoints, snap others
[?] launch both versions
[X] derive gradient descent

Sun 01 Mar 2015 11:53:21 PM PST
tomorrow
[X] test generation functions
[ ] look at some tests where turning wins

Sun 01 Mar 2015 12:05:55 AM PST
[X] write out reward function
[X] investigate gain
[ ] new cost function

Thu 26 Feb 2015 02:23:11 PM PST
[-] git
[-] rewrite features
[ ] extract and test policy vs accelerations and TRL

[X] get policy extraction working
[X] figure out how to save policies
    [X] a type that I can save in a file that represents a policy
    [X] a type that exists in memory
    [X] make_record, extract_record
[ ] run with flat grid with accel action
[ ] run with flat grid with trl actions
[ ] compare all three

[ ] fit kaelbling features in notebook

Wed 25 Feb 2015 09:43:47 AM PST
changed intruder noise to 15 deg from 5
it seems like now 50k simulations is taking ~100 seconds - why?

[X] notebook to demonstrate peaks problem to Marco
[ ] figure out how to save policies
[ ] test policy vs TRL
[ ] rewrite features module

Tue 24 Feb 2015 10:28:27 AM PST
with explicit garbage collection before matrix inversion 100k still uses swap: 260 seconds

Mon 23 Feb 2015 05:45:08 PM PST
no memory help, gc mod 50, 50k sims: 45 seconds 
memory help, gc free, 50k sims: 54 seconds
no memory help, gc free, 50k sims: 121 seconds

Mon 23 Feb 2015 03:54:37 PM PST
For tomorrow
[X] Memory
[ ] extract policy
[ ] Fit Kaelbling Features

[ ] Augment State with Deviation?

Fri 20 Feb 2015 11:24:30 AM PST
[X] Profile Sparse
[ ] Rework features for less allocation
    - 6 workers, 50 k simulations, delayed garbage collection mod 100 = ~45 seconds for simulation
        200 singular values, 85 seconds - matrix inversion ended up with NaNs?
        all singular values, killed after ~8 minutes
        200 singular values, tol = 0.1, 58 seconds - Nans
    [ ] First, run with svds to see if it even works with 50k
[X] refactor actions
[X] Try actions
[ ] extract policy
[ ] Fit Kaelbling Features
[ ] Try Gaussians

Thu 19 Feb 2015 06:52:44 PM PST
[X] refactor value iteration into module
[X] profile
[ ] refactor actions
[ ] extract policy

Wed 18 Feb 2015 05:33:52 PM PST
[ ] grid interpolations for both intruder and goal
[ ] ...

Sun 15 Feb 2015 11:49:10 PM PST
[X] exponential grid
[X] interact
[ ] lit feature justification
[X] homework!!!!

Sun 15 Feb 2015 08:42:00 PM PST
[/] Try with just linear features (no grid)
[X] Try with finer grid

Sun 15 Feb 2015 04:18:48 PM PST
[-] Try pinv instead of SVD

Sat 14 Feb 2015 11:24:20 PM PST
[-] Try moving intruder ?????
[ ] READ!!!

Sat 14 Feb 2015 03:39:28 PM PST
[X] try with intruder eliminated
[X] write brute force evaluator
[X] implement goal grid

Mon 26 Jan 2015 10:25:17 AM PST

[?] add explicit cost features
[ ] ProfileView
[ ] plot r

Fri 23 Jan 2015 01:42:29 PM PST

[ ] define typealias post-decision state
[ ] update decision equations
[ ] run iterations


Sat 10 Jan 2015 04:33:02 PM PST
[ ] define feature function
[ ] solve offline
[ ] run tests

How do I make sure the matrices are full rank?

Future
[ ] Expand TRL to include 

Other ideas
Try this with/without TRL

Tue 13 Jan 2015 12:28:31 AM PST
Junkins and Crassidis p 8
y = step_reward

